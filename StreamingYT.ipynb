{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f594f7-8c8c-43a4-a733-b22917c276df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Function to fetch comments for specific videos (once)\n",
    "def fetch_comments(api_key, video_ids, output_dir):\n",
    "    base_url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "    comments = []\n",
    "\n",
    "    # Fetch comments for each video\n",
    "    for video_id in video_ids:\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"key\": api_key,\n",
    "            \"textFormat\": \"plainText\",\n",
    "            \"maxResults\": 100  # Adjust as needed\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            for item in data.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append({\"video_id\": video_id, \"comment\": comment})\n",
    "        else:\n",
    "            print(f\"Error fetching comments for video {video_id}: {response.status_code}\")\n",
    "\n",
    "    # Save comments to a file\n",
    "    file_path = os.path.join(output_dir, \"comments.json\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for comment in comments:\n",
    "            f.write(json.dumps(comment) + \"\\n\")\n",
    "\n",
    "# Sentiment analysis function using TextBlob\n",
    "def analyze_sentiment(comment):\n",
    "    analysis = TextBlob(comment)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Main function to run sentiment analysis and save results\n",
    "def run_sentiment_analysis():\n",
    "    # *** CONFIGURATION PART - AMEND THIS ***\n",
    "    API_KEY = \"AIzaSyAG53ZyTyJpRO9M7lz6RxRRG_gjOKs1M_4\"  # Replace with your YouTube API key\n",
    "    VIDEO_IDS = [\"xZbcwi7SfZE\", \"EkyAuG9RSSU\", \"CWqSzUNzoUc\"]  # Replace with your video IDs\n",
    "    OUTPUT_DIR = \"comments_stream_dir\"  # Directory for storing comments file\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    # Fetch comments for the given video IDs\n",
    "    fetch_comments(API_KEY, VIDEO_IDS, OUTPUT_DIR)\n",
    "\n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder.appName(\"YouTubeCommentsSentimentAnalysis\").getOrCreate()\n",
    "\n",
    "    # Define schema for incoming JSON data\n",
    "    schema = StructType([\n",
    "        StructField(\"video_id\", StringType(), True),  # video_id column, string type, nullable\n",
    "        StructField(\"comment\", StringType(), True)    # comment column, string type, nullable\n",
    "    ])\n",
    "\n",
    "    # *** CHECK THIS PATH: Ensure your \"comments.json\" is correctly located ***\n",
    "    OUTPUT_DIR = \"C:/Users/labadmin/comments_stream_dir\"\n",
    "    comments_file_path = os.path.join(OUTPUT_DIR, \"comments.json\")\n",
    "    if os.path.exists(comments_file_path):\n",
    "        df = spark.read.json(comments_file_path, schema=schema)\n",
    "    else:\n",
    "        print(f\"No comments file found at {comments_file_path}\")\n",
    "        return\n",
    "\n",
    "    # Show the DataFrame (verify the data is read)\n",
    "    df.show()\n",
    "\n",
    "    # Define UDF for sentiment analysis\n",
    "    sentiment_udf = udf(analyze_sentiment, StringType())\n",
    "\n",
    "    # Apply transformations to perform sentiment analysis on comments\n",
    "    sentiment_df = df.withColumn(\"sentiment\", sentiment_udf(col(\"comment\"))).select(\"video_id\", \"comment\", \"sentiment\")\n",
    "\n",
    "    # *** CHECK THIS OUTPUT PATH: Specify where the sentiment analysis results will be saved ***\n",
    "    output_path = \"C:/Users/labadmin/comments_stream_dir\"\n",
    "    sentiment_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "    #degugging operation\n",
    "    \n",
    "    try:\n",
    "        sentiment_df.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "        print(f\"Sentiment analysis results saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing results to CSV: {e}\")\n",
    "\n",
    "\n",
    "    # Show results in the console\n",
    "    sentiment_df.show()\n",
    "\n",
    "    run_sentiment_analysis()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e794-8467-4bed-9eb7-d61c151cf13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
